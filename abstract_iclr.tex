\begin{abstract}
To acquire a new skill, humans learn better and faster if a private tutor, based on their current knowledge level, inform them whether they should pay extra attention to a practice problem. Similarly, a machine learning model could potentially be trained more efficiently with instructions on the importance of a training data that dynamically ``adapt'' to its current learning state. Meanwhile, identifying the optimal and dynamic importance measure for training any model is a challenging problem, because in order to quantify the effect of a modification to training data importance at a given time during the training, one needs to wait for the whole training process to finish. 
In this paper, we propose Differentiable Adaptive Weighting~(\dds), a novel method for selecting high-quality training data. We formulate the training data importance weight as a parameterized function that is updated along with the main model being trained. The formulation allows direct differentiation to optimize the adaptive data weight, and we show that the derived update rule is equivalent to Reinforcement Learning update with an intuitive reward function. Without significant computing overhead, \dds~delivers strong and consistent improvements on two modalities. Specifically, on multilingual machine translation, \dds~can dynamically identify which related languages are helpful to improve the translation of another language, leading to consistent improvements over a strong heuristic data selection baseline. On image classification tasks with CIFAR-10 and ImageNet, and with different ranges of data, \dds~can also optimize the importance of different training instances throughout training, leading to consistent improvements over the baselines in all settings.\footnote{We will release the code after the paper get accepted.}

\end{abstract}