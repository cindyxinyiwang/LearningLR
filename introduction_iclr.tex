\section{\label{sec:intro} Introduction}
To train a deep learning model, the standard method is to perform uniform stochastic gradient update steps on batches of training data, although the data provided might have many differences in quality, structure or domain properties. Many prior work strive to improve model performance by designing better data selection strategies. Research on data filtering has found that removing noisy data, or selecting in-domain or structurally similar data can lead to large improvements in model performance while potentially reducing the training time~\citep{jiang-zhai-2007-instance,wang-etal-2017-instance,axelrod2011domain,foster-etal-2010-discriminative,moore2010intelligent}. More broadly, data selection can help transfer learning and domain adaptation, where good strategies on using data from a resource rich domain/task can significantly improve the target domain/task we are interested in. For example, while training on data from related high-resource languages is an effective approach for improve the model performance on low-resource languages, identifying the good related languages to use is crucial for a competitive model~\citep{TCS}. 
%Another related line of research is curriculum learning, which improves the model performance by presenting the model easy examples first and then moving towards harder examples~\citep{cl_bengio}.      

There are several challenges shared by existing approaches on training data selection: first, the design of data filtering/selection criterion relies on domain-specific knowledge and hand-picked heuristics; second, most data usage strategies are predefined before the training start and thus is deterministic throughout the training process. 
%Although curriculum learning generally applies different data order at different training steps, the curriculum is a predefined ordering which cannot adapt to the model once training starts. 
Given the existing challenges, we ask the question: ``can we design an algorithm that automatically and efficiently learn the optimal training data that can adapt to the training state of any given learning model?''

We propose a general algorithmic framework for automatic data selection that works by optimizing a data weighting function throughout the training process. We formulate the training objective of the model itself as a weighted sum of the \textit{training} loss using a scoring function. We then optimize this scoring function so that the learned model parameters minimize the loss on the \textit{development} set. The optimization of adaptive data weight can be framed as a Reinforcement Learning problem, where we provide an intuitive reward function: given a model state, training data that has similar gradients with the dev data gets higher reward. Then we directly derive the update rule from the mathematical formulation and show that the gradient of the data weighting is equivalent to the proposed reward function. We name this method ``Differentiable Adaptive Weighting~(\dds)'', because the update rule allows us to directly optimize the data scoring function using back-propagation.

We demonstrate two concrete instantiations of the \dds~framework, one for a more general case of image classification, and the other for a more specific use case on neural machine translation~(NMT). For image classification, we test the algorithm on both CIFAR-10 and ImageNet. For NMT, we focus on a multilingual setting, where we select data from a multilingual corpus to improve the performance on a particular language. 