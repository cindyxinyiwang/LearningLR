\section{\label{sec:intro} Introduction}
%\gn{Overall comment: I think we need to decide the order in which we present the Image Classification/MT results and be consistent about this order. Currently MT is mentioned first in the intro, image classification is mentioned first in Section 3, and MT is mentioned first again in Section 4. A-priori, if your impression is that the experiments for both are equally good/impressive then I'd do image classification first, as it's a simpler case (MT has the additional step of sampling $y$ from the uniform distribution first, which is a little unique), and also more familiar to the ML community. If you feel the MT results are stronger than the image classification results then that might be an argument for putting MT first though. (UPDATE:) actually, reading more I feel pretty strongly that it'd be best to discuss image classification first, as it's more generic.}

While deep learning models are remarkably good at fitting large data sets, they are also highly sensitive to the quality, or even structural or domain properties of the data with which they are provided.
Prior work has found that removing noisy data, or selecting in-domain or structurally similar data can lead to large improvements in model performance while potentially reducing the training time~\citep{jiang-zhai-2007-instance,wang-etal-2017-instance,axelrod2011domain,foster-etal-2010-discriminative,moore2010intelligent}. Most of the existing data selection methods involve heuristics designed through domain-specific knowledge, which are difficult to generalize across tasks and have no guarantees of optimality.
In this paper, we ask the question: ``can we design an algorithm that automatically and efficiently learn the optimal training data for any given learning model?''

We propose a general algorithmic framework for automatic data selection that works by optimizing a data scoring function throughout the training process. We formulate the training objective of the model itself as a weighted sum of the \textit{training} loss using a scoring function. We then optimize this scoring function so that the learned model parameters minimize the loss on the \textit{development} set. The solution of this mathematical formulation leads to a simple optimization rule for the data scoring function: it should upweight the training instances that have similar gradients with the gradients of the development data. We name this method ``Differentiable Data Selection~(\dds)'', because the update rule allows us to directly optimize the data scoring function using back-propagation. 

We demonstrate two concrete instantiations of the \dds~framework, one for a more general case of image classification, and the other for a more specific use case on neural machine translation~(NMT). For image classification, we test the algorithm on both CIFAR-10 and ImageNet. For NMT, we focus on a multilingual setting, where we select data from a multilingual corpus to improve the performance on a particular language. 