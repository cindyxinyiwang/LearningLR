\section{\label{sec:intro} Introduction}

While deep learning models are remarkably good at fitting large data sets, they are also highly sensitive to the quality, or even structural or domain properties of the data with which they are provided.
Prior work has found that removing noisy data, or selecting in-domain or structurally similar data can lead to large improvements in model performance while potentially reducing the training time~\citep{jiang-zhai-2007-instance,wang-etal-2017-instance,axelrod2011domain,foster-etal-2010-discriminative,moore2010intelligent}. Most of the existing data selection methods involve heuristics designed through domain-specific knowledge, which are difficult to generalize across tasks and have no guarantees of optimality.
In this paper, we ask the question: ``can we design an algorithm that automatically and efficiently learn the optimal training data for any given learning model?''

We propose a general algorithmic framework for automatic data selection that works by optimizing a data scoring function throughout the training process. We formulate the training objective of the model itself as a weighted sum of the \textit{training} loss using a scoring function. We then optimize this scoring function so that the learned model parameters minimize the loss on the \textit{development} set. The solution of this mathematical formulation leads to a simple optimization rule for the data scoring function: it should upweight the training instances that have similar gradients with the gradients of the development data. We name this method ``Differentiable Data Selection~(\dds)'', because the update rule allows us to directly optimize the data scoring function using back-propagation. 

We demonstrate two concrete instantiations of the \dds~framework, one for a more general case of image classification, and the other for a more specific use case on neural machine translation~(NMT). For image classification, we test the algorithm on both CIFAR-10 and ImageNet. For NMT, we focus on a multilingual setting, where we select data from a multilingual corpus to improve the performance on a particular language. 